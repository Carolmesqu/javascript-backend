Podemos pensar em novas formas de “atacar” um problema de ordenação, 
começando a partir de partes menores já ordenadas e unindo estas partes 
em uma única lista ordenada;

Evoluímos o conceito e testamos o funcionamento do algoritmo com uma 
simulação sem código, similar ao “teste de mesa”, para entendermos quais 
operações deverão ser feitas pelo código durante o fluxo de execução do programa;

Após utilizarmos a simulação para entendermos o fluxo do algoritmo e o 
que ele deve fazer, desenvolvemos um código em JavaScript para implementá-lo 
através da função juntaListas(), que percorre cada uma das duas listas informadas 
por parâmetro, compara os valores de cada uma, posiciona estes valores em uma lista 
única de acordo com o resultado da comparação e, por fim, retorna a lista unida.

------------------------------------------------------------------------------

Acredite ou não, o objeto console do nosso amigo JavaScript tem muito mais métodos 
do que o log().

Ele também conta com um método chamado trace() que, além de imprimir mensagens, 
também fornece um stack trace, uma espécie de rastro de execução das funções executadas.

De forma bem simples, o trace() vai mostrar o caminho percorrido pelo programa 
até chegar ao ponto em que a função console.trace() é chamada.

Vamos ver no código?
Para fazermos um teste, vamos criar um arquivo index.js e nele uma função 
chamada ola() e outra chamada mundo():

function ola(){
    function mundo() {
        console.trace('Ola Mundo');
      }
  mundo();
}

ola();

A saída no seu terminal será assim:

Trace: Ola Mundo
    at mundo (file:///<diretorio>/index.js:3:15)
    at ola (file:///<diretorio>/index.js:5:1)
    at file:///<diretorio>/index.js:8:1
    at ModuleJob.run (internal/modules/esm/module_job.js:140:23)
    at async Loader.import (internal/modules/esm/loader.js:165:24)
    at async Object.loadESM (internal/process/esm_loader.js:68:5)

Como podemos ver, o método console.trace() imprime a mensagem "Ola Mundo" 
no topo e depois apresenta todo o caminho percorrido nos locais em que o 
console.trace() foi chamado.

Aqui a função ola() é chamada primeiro e a função mundo() é chamada 
posteriormente (observe que na lateral direita aparece o número da linha 
em que o console.trace() é chamado, que é o número "3").

O console.trace() é muito vantajoso quando pensamos em cenários complexos, 
pois fornece um stack trace (rastreamento de pilha) completo, com informações 
sobre os locais, módulos ou arquivos em que os métodos são chamados.

Esse método funciona como ferramenta importante para encontrarmos bugs e atua 
de mãos dadas com o interpretador. Essa prática é possível graças ao motor de 
interpretação do JavaScript (também chamado de engine) que utiliza uma pilha 
de chamadas (call stack) como regra de execução de funções. A pilha de chamadas 
trabalha com a estrutura de dados conhecida como pilha, que tem como regra que 
"o último a entrar é o primeiro a sair" - uma sigla conhecida na programação 
como LIFO, last-in-first-out.

Isso significa que, sempre que executarmos um script, o motor JavaScript 
organiza a execução de forma global e insere a execução da última função 
chamada no topo de pilha de chamadas.

Imagine blocos empilhados um em cima do outro, ou uma pilha de pratos. Se 
tentarmos retirar o último bloco ou o último prato, o que acontece? Certamente 
tudo irá desmoronar, e é assim que a pilha de chamadas funciona também; o motor 
JavaScript executa a última função chamada e se uma função chamar outra em seu 
escopo, um novo contexto de execução será criado e colocará a nova função no 
topo da pilha de chamadas.

O script só finaliza a execução quando a pilha de chamadas estiver vazia.

------------------------------------------------------------------------------

Utilizamos a recursão para construir o algoritmo do merge sort para que a lógica 
de dividir o array em partes cada vez menores pudesse se repetir até que restasse 
apenas um elemento.

R: A recursão trabalha com a ideia de resolver um problema por partes menores, 
até que o problema esteja resolvido por completo. O que é parte do conceito 
por trás do funcionamento do próprio algoritmo do merge sort.

Nesta aula conhecemos o conceito de dividir para conquistar, que envolve quebrar 
um problema em partes menores até que estejam simples o suficiente para serem resolvidos.

R: Como vimos nos algoritmos selection sort e insertion sort, muitas vezes tentar ordenar 
um grande número de dados de uma vez não é eficiente. O paradigma de programação “dividir 
para conquistar” utiliza recursão para dividir o problema.

------------------------------------------------------------------------------

Expandimos o conceito de “dividir para conquistar”, reutilizando a lógica de ordenar 
duas listas, e desenvolvemos um algoritmo para ordenar uma única lista;

Utilizando o recurso das simulações e testes, entendemos o funcionamento de um algoritmo 
de ordenação muito utilizado no dia-a-dia, o Merge Sort;

Após entendermos o fluxo do algoritmo, fizemos a implementação do algoritmo Merge Sort 
com JavaScript, através da função mergeSort() que recebe um array e retorna este array 
ordenado;

Estudamos a ferramenta de recursão, como ela pode ser utilizada no algoritmo Merge Sort 
e as diferenças dessa ferramenta com relação aos laços de repetição.

------------------------------------------------------------------------------

Posicionar o pivô no meio do array é uma das opções para este algoritmo, mas poderia 
ser um elemento escolhido de forma aleatória ou o último elemento do array.

R: Para o algoritmo, não há diferença em posicionar o pivô entre qualquer uma destas 
três opções - você pode fazer o teste de mesa e observar o comportamento dos elementos. 
Porém, haverá mudança no código!

Em nosso código, utilizamos sempre o elemento do meio do array como pivô para separar 
maiores e menores, porém a posição do pivô com relação ao array completo vai sendo 
modificada durante a ordenação.

R: Conforme vimos durante as aulas, o array original vai ser “fatiado” em pequenas 
partes, e sempre que isso acontece é definido um novo pivô a partir do meio do array.

Posicionar o pivô no primeiro elemento do array pode levar o algoritmo a se comportar 
no pior caso possível, se o array já tiver algum tipo de ordenação interna.

R: Observando a simulação que fizemos na aula, vemos que a ordenação do array é feita 
em partes bem pequenas para que depois ele seja reconstruído. Desconstruir essas 
partes já ordenadas, para desordená-las temporariamente e só depois reconstruí-las 
não é uma boa escolha.

------------------------------------------------------------------------------

Trabalhamos com o conceito de pivô, entendemos como selecionar um elemento pivô no 
código e como posicionar este elemento em uma lista, comparando valores e contando 
elementos menores;

Após posicionar um elemento pivô em um array, desenvolvemos um código em JavaScript 
que percorre uma lista e separa todos os elementos entre maiores e menores que o pivô, 
através da função encontraMenores();

A partir do conceito de elemento pivô, entendemos o funcionamento do algoritmo de ordenação 
quick sort, fazendo mais simulações e testes;

Após entendermos o algoritmo, implementamos o código utilizando JavaScript e reaproveitando 
funções e conceitos das aulas anteriores, como a função trocaLugar() e a recursão.

------------------------------------------------------------------------------

Vamos ver um pouco mais a fundo o que significa o erro RangeError: Maximum call stack size 
exceeded visto anteriormente.

A pilha de chamadas
Em programação, uma pilha é uma estrutura de dados onde o último item adicionado é o primeiro 
a ser removido - como uma pilha de livros no mundo real, por exemplo. Também nos referimos 
como pilha (ou stack) a estrutura onde estão “empilhados” os processos que estão sendo executados
em um programa.

Nem todo interpretador ou linguagem de programação lida da mesma forma com os processos que devem 
ser executados por um programa. O NodeJS trabalha com o paradigma de programação orientada a eventos 
(event driven programming), e o gerenciamento dos processos ocorre através do que chamamos de loop 
de eventos.

Não vamos entrar em detalhes aqui sobre como ocorrem a entrada e a saída de processos deste loop e a 
forma como o Node trabalha com threads e programação assíncrona - são assuntos complexos o suficiente 
para terem seus próprios cursos. Porém, vale mencionar aqui que, assim como em outras linguagens de 
programação, o JavaScript também trabalha com pilhas de chamadas. No NodeJS, esta pilha faz parte da 
estrutura do loop de eventos; quando uma função é chamada por um programa ela entra na stack, ou seja, 
na pilha de execução, onde apenas um processo é executado por vez e o próximo processo só é executado 
após a finalização do processo atual.

Esta pilha tem uma quantidade limitada de processos que podem ser empilhados (o que depende de muitos 
fatores, como memória disponível, arquitetura, etc); caso o interpretador não consiga limpar a pilha, 
ou seja, executar e finalizar os processos/funções que estão empilhados, ao atingir o limite o programa 
cai no chamado erro de estouro de pilha, também chamado de stack overflow (daí o nome do famoso fórum de 
programação).

Um dos motivos mais comuns para o estouro de pilha são justamente as chamadas recursivas onde o caso base 
(como vimos na atividade “Para Saber Mais” da aula 2) não existe ou não foi definido da forma correta. Sem 
o caso base, as funções recursivas não param de ser chamadas e vão se empilhando na pilha de chamadas, 
até que não haja mais recursos para processar o programa.

No caso do exemplo visto durante a aula, o NodeJS retorna o erro RangeError: Maximum call stack size exceeded, 
ou “tamanho máximo da pilha de chamadas excedido” e encerra a execução.

Por isso, é muito importante sempre testar as funções recursivas e definir quando interromper a recursividade.

------------------------------------------------------------------------------

 busca binária utiliza recursão de uma forma similar ao merge sort e ao quick sort para dividir o array em partes 
 cada vez menores.

 R: A cada chamada recursiva, o array é dividido em seções cada vez menores, e o valor buscado é situado entre à 
 esquerda (menor) ou à direita (maior) do que o elemento central. Dessa forma, é possível descartar metade dos 
 elementos de cada seção, a cada chamada da função.

 A busca binária é mais eficiente em termos de quantidade de operações necessárias do que a busca linear.

 R: Conforme as simulações feitas durante a aula, é possível localizar um elemento em um array com um número 
 máximo de operações muito menor do que a busca linear.

 ------------------------------------------------------------------------------

Aplicamos novamente o paradigma “dividir para conquistar” para desenvolver o algoritmo de busca chamado busca binária;

Utilizamos recursão para manipular um array ordenado e buscar um elemento, seguindo o fluxo da busca binária que foi 
visto nas simulações e testes;

Desenvolvemos código em JavaScript para implementar o algoritmo de busca binária;

Continuamos a prática de funções recursivas, vendo o funcionamento do “caso base”, que pode ser considerada como a 
condição de parada de uma função recursiva.

------------------------------------------------------------------------------

No dia a dia do trabalho, é muito comum usarmos métodos nativos - ou seja, aqueles que já são próprios da 
linguagem e só precisam ser “chamados” como funções - para que nosso código fique mais legível ou então para 
simplificar o trabalho. Exemplos bem comuns são os métodos sort() e find(), respectivamente usados para 
ordenação e busca.

O método sort() molda elementos de um array em strings e os ordena em ordem crescente. Vamos ver um exemplo?

let numeros = [1, 2, 3, 101, 20, 3, 30, 31, 40];
numeros.sort();
console.log(numeros);

// Saída
// [1, 101, 2, 20, 3, 3, 30, 31, 40]

Observe que a saída mostra a classificação dos números um pouco diferente do esperado. Isso ocorre pois o 
método trata os elementos do array como strings e os coloca em ordem sequencial de acordo com sua posição 
na tabela ASCII, onde 20 vem antes de 3.

Para que o sort() funcione de acordo com o esperado, precisamos passar os parâmetros de comparação de forma 
explícita:

var numbers = [4, 2, 5, 1, 3];
numbers.sort(function(a, b) {
  return a - b;
});
console.log(numbers);
// Saída 
//[1, 2, 3, 4, 5]

Indo além do uso do método no dia a dia, já imaginou como esses métodos funcionam “por baixo dos panos”? 
Não é somente uma palavra para complementar seu código, pois assim como criamos funções, os métodos 
nativos da linguagem também possuem lógica e algoritmos por trás. Vamos conhecer um pouco mais?

No JavaScript, a forma como o método é implementado depende do motor que faz a interpretação. 
A partir de cada versão aprovada do JavaScript pelo ECMA, as empresas ou fundações responsáveis 
pelos navegadores/interpretadores (chamadas de vendors no jargão da área) decidem e fazem a 
implementação das funcionalidades.

No caso do motor V8, utilizado pelo Chrome/NodeJS, o sort() tem em sua implementação os algoritmos 
quick sort - ordenação rápida e insertion sort - ordenação por inserção, e funcionam da seguinte maneira:

 function QuickSort(a, from, to) {
    var third_index = 0;
    while (true) {
      // Insertion sort is faster for short arrays.
      if (to - from <= 10) {
        InsertionSort(a, from, to);
        return;
      }

Por outro lado, no motor SpiderMonkey, utilizado pelo Firefox, o algoritmo utilizado por trás do método sort() 
é o merge sort, implementado abaixo em C++:

JSBool
js::array_sort(JSContext *cx, uintN argc, Value *vp)
{
    jsuint len, newlen, i, undefs;
    size_t elemsize;
    JSString *str;

    Value *argv = JS_ARGV(cx, vp);
    Value fval;
    if (argc > 0 && !argv[0].isUndefined()) {
        if (argv[0].isPrimitive()) {
            JS_ReportErrorNumber(cx, js_GetErrorMessage, NULL, JSMSG_BAD_SORT_ARG);
            return false;
        }
        fval = argv[0];     /* non-default compare function */
    } else {
        fval.setNull();
    }

    JSObject *obj = ToObject(cx, &vp[1]);
    if (!obj)
        return false;
+
−    if (!js_GetLengthProperty(cx, obj, &len))
        return false;
    if (len == 0) {
        vp->setObject(*obj);
        return true;
    }

    /*
     * We need a temporary array of 2 * len Value to hold the array elements
     * and the scratch space for merge sort. Check that its size does not
     * overflow size_t, which would allow for indexing beyond the end of the
     * malloc'd vector.
     */
#if JS_BITS_PER_WORD == 32
    if (size_t(len) > size_t(-1) / (2 * sizeof(Value))) {
        js_ReportAllocationOverflow(cx);
        return false;
    }

    ------------------------------------------------------------------------------

Durante o desenvolvimento do código do quick sort, comentamos sobre o pior caso de execução 
de um algoritmo.

Em algoritmos, os termos melhor caso e pior caso se referem à quantidade de recursos a ser 
utilizado na execução, que pode ser tempo de execução ou memória.

Uma maneira adotada para mensurar a eficiência dos algoritmos, tendo em vista tempo de 
execução e espaço de memória, é por meio da notação Big O, que realiza a comparação 
desses dois parâmetros.

Lembrando que a notação Big O se refere a uma classificação de algoritmos de acordo 
com o tempo de execução, à medida em que aumenta a quantidade de dados a serem manipulados 
e a quantidade de memória exigida.

Dessa forma, teremos o melhor caso de algoritmo quando ele apresenta a mesma quantidade de 
tempo para executar, independente do tamanho da entrada. E um pior caso quando se tem um 
maior tempo de execução considerando todas as possíveis entradas.

Exemplo de Big O em algoritmos de ordenação:    


Algoritmo	estrutura	Complex. tempo: melhor caso	Complex. tempo: pior caso	Complex. espaço: pior caso
Quick Sort	    Array	O(n log(n))	                        O(n²)	                    O(n log(n))
Merge Sort	    Array	O(n log(n))	                        O(n log(n))	                O(n)
Heap Sort	    Array	O(n log(n))	                        O(n log(n))	                O(1)
Smooth Sort	    Array	O(n)	                            O(n log(n))	                O(1)
Bubble Sort	    Array	O(n)	                            O(n²)	                    O(1)
Insertion Sort	Array	O(n)	                            O(n²)	                    O(1)
Selection Sort	Array	O(n²)	                            O(n²)	                    O(1)

Onde:

O(1): notação de Big O que representa um algoritmo que é executado em tempo constante.

O(n): algoritmo que é executado em tempo linear, ou seja, as execuções aumentam de acordo com as entradas - como a busca linear.

O(n log(n)): representa um algoritmo que reduz pela metade uma lista a cada vez que é executado - como o merge sort e o quick sort.

O(n²): algoritmo com o tempo quadrático que por sua vez, significa que assim que o número de elementos na entrada aumenta, as execuções
aumentam quadraticamente. Por isso, devemos evitar códigos com essa notação de Big O, pois o número de operações aumenta 
significativamente a cada entrada - como o selection sort e o insertion sort.


------------------------------------------------------------------------------

Em computação sempre é utilizado o logaritmo com base 2 (e, consequentemente, o inverso é a potência de 2). Assim, 
log n representa de forma abreviada log2 n, ou seja, log de n na base 2.

Esta característica está ligada ao sistema numérico utilizado pelos computadores: o sistema binário (ou de base 2), 
onde todos os valores são representados pelos números 0 e 1.

Assim, sempre que trabalharmos com valores O(log n), estamos nos referindo a base 2.

------------------------------------------------------------------------------

Tanto o merge sort quanto o quick sort executam operações linearmente (n) e também em (log n), então é um algoritmo 
de complexidade n log(n).

Analisando o código do merge sort:

R: O código está baseado na função ordena (que compara e monta o array final) e na função mergeSort que divide o array para ser ordenado.
A função ordena percorre o array passado por parâmetro com um loop while, então podemos considerar que ela vai percorrer os arrays 
fornecidos de forma linear.
A função mergeSort, a cada vez que é chamada, divide o array em 2 partes cada vez menores - ou seja, a cada chamada apenas uma parte 
cada vez menor do array original é percorrida.
Unindo as operações feitas pelo algoritmo (linear e logarítmica) temos a expressão O(n log(n)).

Valores de crescimento logarítmico ou O(log(n)), são números que, colocados como potência, resultam na quantidade de elementos que 
estamos buscando. Por exemplo, o log de 1024 na base 2 é 10, pois 2x2x2x2x2x2x2x2x2x2 = 1024.

R: Conforme visto nas simulações, é possível expressar a complexidade de um algoritmo logarítmico da seguinte forma:

Com 1 operação, analisamos uma lista de 2^1 = 1 elemento
Com 2 operações, analisamos uma lista de 2^2 = 4 elementos
Com 3 operações, analisamos uma lista de 2^3 = 8 elementos
Com 4 operações, analisamos uma lista de 2^4 = 16 elementos
Com 10 operações, analisamos uma lista de 2^10 = 1024 elementos

O paradigma “dividir para conquistar” resulta em algoritmos mais eficientes do que os que atacam um problema inteiro de uma vez só.

R: O paradigma “dividir para conquistar” quebra um problema e o resolve em partes menores, para que uma vez unidas estas partes, 
o problema inteiro se resolva. A eficiência está em trabalhar com quantidades menores de operações.

------------------------------------------------------------------------------

Aprendemos a fazer a análise assintótica do algoritmo de busca binária e por que este é considerado um 
algoritmo de complexidade logarítmica, em comparação com a busca linear que é um algoritmo de complexidade linear;

Fizemos a análise assintótica dos algoritmos de ordenação quick sort e merge sort e analisamos o código 
para entendermos por que são considerados algoritmos de complexidade linear-logarítmica;

E o que significa, em termos de performance, a diferença entre algoritmos de crescimento linear, quadrático e logarítmico.